{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eaf87f8",
   "metadata": {},
   "source": [
    "# Wisconsin Diagnostic Breast Cancer Dataset Analysis\n",
    "## A Clinical AI Exercise for MD-PhD Students\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand the biological basis of quantitative cytology in cancer diagnosis\n",
    "- Apply supervised and unsupervised machine learning to real clinical data\n",
    "- Develop hypothesis-driven feature selection strategies\n",
    "- Interpret model results in a clinical context\n",
    "- Investigate tumor heterogeneity and patient-specific phenotypes\n",
    "\n",
    "---\n",
    "\n",
    "## Part I: Understanding the Wisconsin Breast Cancer Dataset (WDBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fffddb",
   "metadata": {},
   "source": [
    "### 1.1 Dataset Origin & Clinical Context\n",
    "\n",
    "**What is WDBC?**\n",
    "The Wisconsin Diagnostic Breast Cancer (WDBC) dataset contains morphological measurements of cell nuclei from Fine-Needle Aspiration (FNA) biopsies of breast masses. This dataset was collected at the University of Wisconsin Clinical Sciences Center (1991-1995) by Dr. William Wolberg and colleagues.\n",
    "\n",
    "**Clinical Procedure: Fine-Needle Aspiration (FNA)**\n",
    "- FNA is a minimally invasive diagnostic procedure using a thin needle (23-25 gauge) to sample cells from a suspicious breast lesion\n",
    "- Cells are prepared on glass slides and visualized under microscopy\n",
    "- Cytopathologists manually outline cell nuclei and measure ~30 morphological features\n",
    "- This approach bridges between clinical urgency (rapid diagnosis) and accuracy\n",
    "\n",
    "**The Features: From Microscopy to Data**\n",
    "The dataset includes **30 continuous features** derived from digitized images of FNA slides, organized in three groups:\n",
    "\n",
    "| Group | Features | Biological Meaning |\n",
    "|-------|----------|-------------------|\n",
    "| **Standard statistics (10)** | radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, fractal dimension | Single value per nucleus |\n",
    "| **Mean values (10)** | Mean of each standard feature across the nucleus | Aggregate nuclear characteristics |\n",
    "| **Standard error (10)** | SE of each standard feature | Variability within the nucleus |\n",
    "\n",
    "**Target Variable: Diagnosis**\n",
    "- **M (Malignant)**: Cancerous nuclei (212 cases)\n",
    "- **B (Benign)**: Non-cancerous nuclei (357 cases)\n",
    "- Binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293e96d7",
   "metadata": {},
   "source": [
    "### 1.2 Image Analysis Pipeline: From Microscopy to Quantification\n",
    "\n",
    "```\n",
    "Microscopy Slide with FNA sample\n",
    "    â†“\n",
    "Digital Image Acquisition (CAS-200 instrument)\n",
    "    â†“\n",
    "Image Segmentation: Identify cell nuclei boundaries\n",
    "    â†“\n",
    "Feature Extraction: Measure 30 morphological properties per nucleus\n",
    "    â†“\n",
    "Statistical Analysis: Mean, standard error of measurements\n",
    "    â†“\n",
    "Clinical Interpretation: M vs B classification\n",
    "```\n",
    "\n",
    "**Why These Features?**\n",
    "Malignant tumors typically show:\n",
    "- **Larger, more irregular nuclei** (â†‘ radius, â†‘ perimeter, â†‘ area)\n",
    "- **Increased nuclear complexity** (â†‘ concavity, â†‘ concave points)\n",
    "- **Loss of uniformity** (â†“ symmetry, â†‘ texture variation)\n",
    "- **Abnormal texture patterns** (â†‘ compactness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f36d1e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part II: Setting Up Your Environment\n",
    "\n",
    "To run this exercise, you'll need:\n",
    "\n",
    "**Python packages:**\n",
    "```yaml\n",
    "# environment.yml - Create conda environment with:\n",
    "# conda env create -f environment.yml\n",
    "\n",
    "name: breast_cancer_analysis\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.11\n",
    "  - pandas\n",
    "  - numpy\n",
    "  - scikit-learn\n",
    "  - matplotlib\n",
    "  - seaborn\n",
    "  - plotly\n",
    "  - xgboost\n",
    "  - jupyter\n",
    "```\n",
    "\n",
    "**Installation:**\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "conda activate breast_cancer_analysis\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277095b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Load the Wisconsin Breast Cancer Dataset from scikit-learn\n",
    "# ============================================================================\n",
    "\n",
    "# Core data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    roc_curve, precision_recall_curve, f1_score, accuracy_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")\n",
    "print(f\"Python environment configured for clinical AI analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Load the Wisconsin Breast Cancer Dataset from local files\n",
    "# ============================================================================\n",
    "\n",
    "# Path to local data files\n",
    "data_path = r'C:\\Users\\user\\Documents\\Einan\\all_sorts\\learning\\code_exercise_build\\breast_cancer_wisconsin_diagnostic'\n",
    "\n",
    "# Load variable names\n",
    "var_names = pd.read_csv(f'{data_path}\\\\var_names.tsv', sep='\\t')\n",
    "column_names = var_names['Variable Name'].tolist()\n",
    "\n",
    "# Load WDBC data\n",
    "df = pd.read_csv(f'{data_path}\\\\wdbc.data', header=None, names=column_names)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(['ID', 'Diagnosis'], axis=1)\n",
    "y = df['Diagnosis'].map({'M': 1, 'B': 0})  # 1 = Malignant, 0 = Benign\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Samples: {X.shape[0]}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nClass balance: {y.value_counts()[0]} Benign ({y.value_counts()[0]/len(y)*100:.1f}%), \"\n",
    "      f\"{y.value_counts()[1]} Malignant ({y.value_counts()[1]/len(y)*100:.1f}%)\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41ce0a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part III: Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Exercise 3.1: Descriptive Statistics & Feature Discrimination\n",
    "\n",
    "**Your Task:**\n",
    "Generate summary statistics for benign and malignant tumors separately. Identify which morphological features show the **largest and most clinically meaningful differences** between the two groups.\n",
    "\n",
    "**Hint:** Look for features with large effect sizes (Cohen's d > 0.8), which indicate strong discrimination potential.\n",
    "\n",
    "**Clinical Question to Consider:**\n",
    "Which nuclear properties best distinguish cancer from normal tissue? Do all top discriminative features make biological sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44239b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXERCISE 3.1: COMPUTE DESCRIPTIVE STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "# Separate data by diagnosis group\n",
    "# This allows us to compare benign vs malignant characteristics\n",
    "df_benign = X[y == 0]\n",
    "df_malignant = X[y == 1]\n",
    "\n",
    "# Create a comprehensive comparison table\n",
    "# For each feature, we calculate: mean values, difference, fold-change, and effect size\n",
    "comparison = pd.DataFrame({\n",
    "    'Benign_Mean': df_benign.mean(),\n",
    "    'Malignant_Mean': df_malignant.mean(),\n",
    "    'Difference': df_malignant.mean() - df_benign.mean(),\n",
    "    'Fold_Change': df_malignant.mean() / df_benign.mean()\n",
    "})\n",
    "\n",
    "# Calculate Cohen's d: standardized effect size\n",
    "# Interpretation: d < 0.2 = small, 0.2-0.5 = small-medium, 0.5-0.8 = medium-large, > 0.8 = large\n",
    "def cohens_d(group1, group2):\n",
    "    \"\"\"\n",
    "    Calculate Cohen's d effect size between two groups.\n",
    "    \n",
    "    This standardized measure is independent of sample size and feature scale,\n",
    "    making it ideal for comparing features with different units.\n",
    "    \n",
    "    Args:\n",
    "        group1, group2: pandas Series or arrays to compare\n",
    "    \n",
    "    Returns:\n",
    "        float: Cohen's d value (positive = group2 > group1)\n",
    "    \"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = group1.var(), group2.var()\n",
    "    # Pooled standard deviation accounts for potentially different variances\n",
    "    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    # Return absolute value for ranking\n",
    "    return (group2.mean() - group1.mean()) / pooled_std\n",
    "\n",
    "# Apply Cohen's d to all features\n",
    "comparison['Cohens_d'] = [\n",
    "    abs(cohens_d(df_benign[col], df_malignant[col])) \n",
    "    for col in X.columns\n",
    "]\n",
    "\n",
    "# Sort by effect size (largest differences at top)\n",
    "comparison_sorted = comparison.sort_values('Cohens_d', ascending=False)\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 100)\n",
    "print(\"FEATURE COMPARISON: BENIGN vs MALIGNANT (Sorted by Effect Size)\")\n",
    "print(\"=\" * 100)\n",
    "print(comparison_sorted.round(3))\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"INTERPRETATION GUIDE\")\n",
    "print(\"=\" * 100)\n",
    "print(\"\"\"\n",
    "Cohen's d Effect Size:\n",
    "  â€¢ d < 0.2  â†’ Small effect (weak discrimination)\n",
    "  â€¢ d = 0.5  â†’ Medium effect (moderate discrimination)\n",
    "  â€¢ d = 0.8  â†’ Large effect (strong discrimination) âœ“\n",
    "  â€¢ d > 1.0  â†’ Very large effect (excellent discrimination) âœ“âœ“\n",
    "\n",
    "Clinical Insight:\n",
    "  Malignant tumors show:\n",
    "  - LARGER nuclei (â†‘ radius, â†‘ area)\n",
    "  - MORE irregular shapes (â†‘ compactness, â†‘ concavity)\n",
    "  - LESS symmetrical (â†“ symmetry)\n",
    "  - INCREASED texture variation\n",
    "\"\"\")\n",
    "\n",
    "# Identify highly discriminative features\n",
    "top_discriminators = comparison_sorted[comparison_sorted['Cohens_d'] > 0.8]\n",
    "print(f\"\\nâœ“ Top discriminative features (|Cohen's d| > 0.8):\")\n",
    "print(f\"  Found {len(top_discriminators)} strong discriminators out of {len(X.columns)} features\\n\")\n",
    "for idx, feature in enumerate(top_discriminators.index, 1):\n",
    "    d_val = top_discriminators.loc[feature, 'Cohens_d']\n",
    "    fold = top_discriminators.loc[feature, 'Fold_Change']\n",
    "    print(f\"  {idx:2d}. {feature:<40} d={d_val:.2f}  (Malignant {fold:.1f}x larger)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690fd1f",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Visualization of Feature Distributions\n",
    "\n",
    "**Your Task:**\n",
    "Create violin plots showing the distribution of the top 6 discriminative features. Compare benign and malignant cases visually.\n",
    "\n",
    "**What to Look For:**\n",
    "- **Separation:** How much overlap is there between groups? High separation = good diagnostic potential\n",
    "- **Skewness:** Are distributions symmetric or skewed? Skewed distributions might indicate distinct tumor subtypes\n",
    "- **Outliers:** Are there exceptional cases that deviate from the pattern?\n",
    "\n",
    "**Discussion Question:**\n",
    "If you were a pathologist looking at a single cell nucleus measurement, could you confidently diagnose malignancy using only the top feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXERCISE 3.2: VISUALIZE FEATURE DISTRIBUTIONS\n",
    "# ============================================================================\n",
    "\n",
    "# Select the top 6 most discriminative features for visualization\n",
    "# These are the features most useful for distinguishing benign from malignant\n",
    "top_6_features = comparison_sorted.head(6).index.tolist()\n",
    "\n",
    "# Create a 2x3 grid of subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('Top 6 Discriminative Features: Benign vs Malignant Distributions', \n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "\n",
    "# For each feature, create a violin plot with overlaid data points\n",
    "for idx, (ax, feature) in enumerate(zip(axes.flatten(), top_6_features)):\n",
    "    # Prepare data for plotting with diagnosis labels\n",
    "    plot_data = pd.DataFrame({\n",
    "        'Value': pd.concat([df_benign[feature], df_malignant[feature]]),\n",
    "        'Diagnosis': ['Benign']*len(df_benign) + ['Malignant']*len(df_malignant)\n",
    "    })\n",
    "    \n",
    "    # Create violin plot (shows full distribution shape)\n",
    "    # followed by strip plot (shows individual data points)\n",
    "    sns.violinplot(data=plot_data, x='Diagnosis', y='Value', ax=ax, \n",
    "                   palette=['#2ecc71', '#e74c3c'], inner=None, alpha=0.6)\n",
    "    sns.stripplot(data=plot_data, x='Diagnosis', y='Value', ax=ax, \n",
    "                  color='black', alpha=0.3, size=2, jitter=True)\n",
    "    \n",
    "    # Format subplot\n",
    "    ax.set_title(f'{feature}\\n(Cohen\\'s d = {comparison_sorted.loc[feature, \"Cohens_d\"]:.2f})', \n",
    "                 fontweight='bold', fontsize=11)\n",
    "    ax.set_ylabel('Normalized Value' if idx % 3 == 0 else '', fontsize=10)\n",
    "    ax.set_xlabel('Diagnosis', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add statistical test result (t-test p-value)\n",
    "    # This tells us if the difference is statistically significant (p < 0.05)\n",
    "    from scipy.stats import ttest_ind\n",
    "    t_stat, p_val = ttest_ind(df_malignant[feature].values, df_benign[feature].values)\n",
    "    \n",
    "    # Format p-value for display\n",
    "    if p_val < 0.001:\n",
    "        p_text = '***\\n(p < 0.001)'\n",
    "    elif p_val < 0.01:\n",
    "        p_text = '**\\n(p < 0.01)'\n",
    "    else:\n",
    "        p_text = f'p = {p_val:.3f}'\n",
    "    \n",
    "    # Add annotation to show statistical significance\n",
    "    ax.text(0.98, 0.97, p_text, transform=ax.transAxes, \n",
    "            fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.6))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DISTRIBUTION ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nâœ“ Plotted top {len(top_6_features)} discriminative features\")\n",
    "print(f\"âœ“ All features show statistically significant differences (p < 0.001)\")\n",
    "print(f\"\\nðŸ“Š Key Observation:\")\n",
    "print(f\"   Good separation between benign and malignant groups suggests\")\n",
    "print(f\"   these features will have high predictive power in machine learning models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073d23b",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Feature Correlation & Redundancy Analysis\n",
    "\n",
    "**Your Task:**\n",
    "Create a correlation heatmap and identify redundant features (highly correlated pairs). \n",
    "\n",
    "**Why This Matters:**\n",
    "- **Redundancy reduction:** Highly correlated features provide overlapping information\n",
    "- **Model efficiency:** Removing redundant features can improve computational speed\n",
    "- **Feature independence:** For interpretability, we prefer uncorrelated predictors\n",
    "- **Biological insight:** Are different measurement types (size, shape, texture) capturing independent information?\n",
    "\n",
    "**Questions to Answer:**\n",
    "1. Which feature pairs are most highly correlated?\n",
    "2. Are certain measurement groups (e.g., \"radius\" variants) more correlated with each other?\n",
    "3. What % of feature variance can be explained by just a few principal components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXERCISE 3.3: CORRELATION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate Pearson correlation coefficient for all feature pairs\n",
    "# Correlation ranges from -1 (perfect negative) to +1 (perfect positive)\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "# Create a large heatmap visualization\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "# Plot correlation heatmap with color gradient\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.3, cbar_kws={\"shrink\": 0.8}, \n",
    "            ax=ax, vmin=-1, vmax=1)\n",
    "\n",
    "ax.set_title('Feature Correlation Matrix - WDBC Dataset\\n(Darker red = stronger positive correlation)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Identify and report highly correlated feature pairs\n",
    "# These pairs have r > 0.95, indicating near-perfect redundancy\n",
    "print(\"=\" * 100)\n",
    "print(\"FEATURE CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Extract upper triangle of correlation matrix to avoid duplicates\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        # Keep pairs with |r| > 0.95 (very high correlation = redundancy)\n",
    "        if abs(corr_value) > 0.95:\n",
    "            high_corr_pairs.append({\n",
    "                'Feature1': correlation_matrix.columns[i],\n",
    "                'Feature2': correlation_matrix.columns[j],\n",
    "                'Correlation': corr_value\n",
    "            })\n",
    "\n",
    "# Sort by absolute correlation (strongest relationships first)\n",
    "high_corr_pairs_sorted = sorted(high_corr_pairs, key=lambda x: abs(x['Correlation']), reverse=True)\n",
    "\n",
    "if high_corr_pairs_sorted:\n",
    "    print(f\"\\nâœ“ Found {len(high_corr_pairs_sorted)} HIGHLY CORRELATED pairs (|r| > 0.95):\\n\")\n",
    "    for idx, pair in enumerate(high_corr_pairs_sorted[:20], 1):\n",
    "        print(f\"  {idx:2d}. {pair['Feature1']:<40} <-> {pair['Feature2']:<40}\")\n",
    "        print(f\"      Correlation: r = {pair['Correlation']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nNo feature pairs with |r| > 0.95 found\")\n",
    "\n",
    "# Calculate how many feature pairs have correlation > 0.9\n",
    "very_high_corr = len([p for p in high_corr_pairs if abs(p['Correlation']) > 0.90])\n",
    "high_corr = len([p for p in high_corr_pairs if abs(p['Correlation']) > 0.85])\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 100)\n",
    "print(\"REDUNDANCY SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\"\"\n",
    "Feature Redundancy Statistics:\n",
    "  â€¢ Pairs with |r| > 0.95: {very_high_corr} (nearly identical information)\n",
    "  â€¢ Pairs with |r| > 0.85: {high_corr} (highly redundant)\n",
    "  \n",
    "Implication:\n",
    "  â†’ DIMENSIONALITY REDUCTION is promising!\n",
    "  â†’ We can likely reduce 30 features to 10-15 principal components\n",
    "     without losing diagnostic information\n",
    "  \n",
    "Biological Interpretation:\n",
    "  â†’ Many \"size\" features (radius, area, perimeter) highly correlate\n",
    "     because they all scale together\n",
    "  â†’ This redundancy is expected: larger tumors are more irregular,\n",
    "     have more concavity, etc.\n",
    "\"\"\")\n",
    "\n",
    "# Calculate dimension reduction potential using PCA\n",
    "# (We'll do detailed PCA later, this is just a preview)\n",
    "from sklearn.decomposition import PCA\n",
    "pca_preview = PCA()\n",
    "pca_preview.fit(X)\n",
    "\n",
    "# How many components explain 95% of variance?\n",
    "cumsum_var = np.cumsum(pca_preview.explained_variance_ratio_)\n",
    "n_components_95 = np.argmax(cumsum_var >= 0.95) + 1\n",
    "\n",
    "print(f\"PCA Preview:\")\n",
    "print(f\"  â€¢ {n_components_95} components explain 95% of variance\")\n",
    "print(f\"  â€¢ Dimension reduction potential: {len(X.columns)} â†’ {n_components_95} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9650cdd6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part IV: Supervised Learning for Diagnosis Prediction\n",
    "\n",
    "### 4.1 Data Preprocessing & Train-Test Split\n",
    "\n",
    "**Clinical Consideration:** In medical AI, we must ensure that models generalize to unseen patients, not just memorize the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcced18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PREPROCESSING & DATA SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "# 1. Train-test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nClass balance in training set:\")\n",
    "print(f\"  Benign: {(y_train == 0).sum()} ({(y_train == 0).sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  Malignant: {(y_train == 1).sum()} ({(y_train == 1).sum()/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "# 2. Feature Standardization (Essential!)\n",
    "# Different features have different scales (e.g., radius ~20, texture ~40)\n",
    "# Most ML algorithms perform better with normalized features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nâœ“ Features standardized (mean=0, std=1)\")\n",
    "print(f\"  Mean of scaled features: {X_train_scaled.mean():.6f}\")\n",
    "print(f\"  Std of scaled features: {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb9d3dd",
   "metadata": {},
   "source": [
    "### 4.2 Feature Selection Strategy: Statistical & Information-Theoretic Approach\n",
    "\n",
    "**Why Select Features?**\n",
    "With 30 features and 569 samples (~19:1 feature-to-sample ratio), we risk **overfitting**: models memorize noise rather than learning generalizable patterns.\n",
    "\n",
    "**Your Strategy:**\n",
    "Use a **composite scoring** approach combining two complementary measures:\n",
    "\n",
    "1. **Cohen's d (Effect Size):** Measures statistical separation between benign/malignant\n",
    "   - High d = feature clearly discriminates between groups\n",
    "   - Independent of sample size\n",
    "\n",
    "2. **Mutual Information:** Measures how much information each feature provides about diagnosis\n",
    "   - High MI = feature contains unique predictive information\n",
    "   - Captures non-linear relationships\n",
    "\n",
    "**Filtering Criterion:** Keep features with composite score > 0.5 (standardized threshold)\n",
    "\n",
    "**Expected Outcome:** Reduce 30 â†’ 10-15 features while maintaining diagnostic accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA PREPROCESSING: TRAIN-TEST SPLIT & STANDARDIZATION\n",
    "# ============================================================================\n",
    "\n",
    "# STEP 1: Split data into training (80%) and testing (20%) sets\n",
    "# Stratification ensures both sets have similar class balance\n",
    "# This mimics real clinical scenarios: train on past patients, test on new ones\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"DATA SPLITTING & STANDARDIZATION\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nTrain-Test Split (stratified):\")\n",
    "print(f\"  Training set:  {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test set:      {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nClass balance preserved in both sets:\")\n",
    "print(f\"  Training:  {(y_train == 0).sum()} Benign, {(y_train == 1).sum()} Malignant\")\n",
    "print(f\"  Test:      {(y_test == 0).sum()} Benign, {(y_test == 1).sum()} Malignant\")\n",
    "\n",
    "# STEP 2: Feature Standardization (Critical!)\n",
    "# Different features have very different ranges:\n",
    "#   - radius: ~10-30\n",
    "#   - texture: ~10-40\n",
    "#   - compactness: ~0.05-0.35\n",
    "# Machine learning algorithms (especially distance-based) perform poorly with unscaled features\n",
    "# Standardization: subtract mean, divide by std â†’ all features have Î¼=0, Ïƒ=1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# fit_transform: learn scaling parameters from TRAINING set, apply to TRAINING set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# transform: apply SAME scaling to TEST set (don't refit!)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nâœ“ Features standardized using StandardScaler\")\n",
    "print(f\"  Mean of scaled features: {X_train_scaled.mean():.6f}\")\n",
    "print(f\"  Std of scaled features:  {X_train_scaled.std():.6f}\")\n",
    "print(f\"  (Should be â‰ˆ0 and â‰ˆ1)\")\n",
    "\n",
    "# Convert scaled arrays back to DataFrames for easier handling\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE SELECTION: COMPOSITE SCORING APPROACH\n",
    "# ============================================================================\n",
    "\n",
    "# Calculate feature importance using TWO complementary methods\n",
    "\n",
    "# METHOD 1: Cohen's d (Effect Size)\n",
    "# Measures how well each feature separates benign from malignant\n",
    "# Formula: (mean_malignant - mean_benign) / pooled_std_dev\n",
    "# Interpretation: d=0.8 = large effect, d=2.0 = very large effect\n",
    "print(\"\\nCalculating Cohen's d for all features...\")\n",
    "\n",
    "cohens_d_values = []\n",
    "for col in X_train_scaled_df.columns:\n",
    "    d = cohens_d(X_train_scaled_df.loc[y_train == 0, col], \n",
    "                  X_train_scaled_df.loc[y_train == 1, col])\n",
    "    cohens_d_values.append(abs(d))\n",
    "\n",
    "# METHOD 2: Mutual Information\n",
    "# Measures how much information each feature provides about diagnosis\n",
    "# High MI = knowing this feature's value greatly reduces uncertainty about diagnosis\n",
    "# Lower MI = feature provides little diagnostic information\n",
    "print(\"Calculating Mutual Information for all features...\")\n",
    "\n",
    "mi_scores = mutual_info_classif(X_train_scaled, y_train, random_state=42)\n",
    "\n",
    "# Create comprehensive feature importance table\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Cohens_d': cohens_d_values,\n",
    "    'Mutual_Information': mi_scores\n",
    "})\n",
    "\n",
    "# Normalize both scores to 0-1 range for fair comparison\n",
    "feature_importance['d_normalized'] = (feature_importance['Cohens_d'] / \n",
    "                                       feature_importance['Cohens_d'].max())\n",
    "feature_importance['mi_normalized'] = (feature_importance['Mutual_Information'] / \n",
    "                                        feature_importance['Mutual_Information'].max())\n",
    "\n",
    "# Create composite score: equal weight to both methods\n",
    "# This balances statistical significance with information content\n",
    "feature_importance['Composite_Score'] = (\n",
    "    feature_importance['d_normalized'] * 0.5 + \n",
    "    feature_importance['mi_normalized'] * 0.5\n",
    ")\n",
    "\n",
    "# Sort by composite score\n",
    "feature_importance_sorted = feature_importance.sort_values('Composite_Score', ascending=False)\n",
    "\n",
    "# Select features with composite score > 0.5\n",
    "# This threshold is data-driven: keeps top ~50% of features\n",
    "selected_features = feature_importance_sorted[\n",
    "    feature_importance_sorted['Composite_Score'] > 0.5\n",
    "]['Feature'].tolist()\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"FEATURE SELECTION RESULTS\")\n",
    "print(\"=\" * 120)\n",
    "print(f\"\\nâœ“ Selected {len(selected_features)} features using composite scoring approach\")\n",
    "print(f\"  Selection method: Composite_Score > 0.5 (top {len(selected_features)/len(X.columns)*100:.0f}% of features)\")\n",
    "print(f\"  Rationale: Balance effect size + information content\\n\")\n",
    "\n",
    "# Show top 20 features with detailed scores\n",
    "print(\"Top 20 Features (ranked by Composite Score):\")\n",
    "print(\"-\" * 120)\n",
    "for idx, (_, row) in enumerate(feature_importance_sorted.head(20).iterrows(), 1):\n",
    "    selected_marker = \"âœ“\" if row['Feature'] in selected_features else \" \"\n",
    "    print(f\"{selected_marker} {idx:2d}. {row['Feature']:<40} \"\n",
    "          f\"Score={row['Composite_Score']:.3f}  \"\n",
    "          f\"(Cohen's d={row['Cohens_d']:.2f}, MI={row['Mutual_Information']:.3f})\")\n",
    "\n",
    "# Prepare selected feature datasets\n",
    "# Extract only selected features from scaled data\n",
    "selected_feature_indices = [X.columns.get_loc(f) for f in selected_features]\n",
    "X_train_selected = X_train_scaled[:, selected_feature_indices]\n",
    "X_test_selected = X_test_scaled[:, selected_feature_indices]\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 120)\n",
    "print(f\"âœ“ Dataset prepared for modeling:\")\n",
    "print(f\"  Original features:  {X_train_scaled.shape[1]}\")\n",
    "print(f\"  Selected features:  {X_train_selected.shape[1]}\")\n",
    "print(f\"  Reduction:          {X_train_scaled.shape[1] - X_train_selected.shape[1]} features removed\")\n",
    "print(f\"  Training samples:   {X_train_selected.shape[0]}\")\n",
    "print(f\"  Test samples:       {X_test_selected.shape[0]}\")\n",
    "print(f\"=\" * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b803c28",
   "metadata": {},
   "source": [
    "### 4.3 Building Three Complementary Diagnostic Models\n",
    "\n",
    "**Question for Discussion:** Why compare multiple algorithms instead of using just one?\n",
    "\n",
    "**Answer:** Different algorithms capture different patterns in the data:\n",
    "- **Logistic Regression:** Linear decision boundaries, highly interpretable, fast\n",
    "  - Best for: Understanding which features drive diagnosis\n",
    "  - Weakness: Cannot capture complex feature interactions\n",
    "  \n",
    "- **Random Forest:** Non-linear boundaries, handles interactions, robust to outliers\n",
    "  - Best for: Prediction accuracy, feature importance ranking\n",
    "  - Weakness: Less interpretable (\"black box\")\n",
    "  \n",
    "- **XGBoost:** Iterative gradient boosting, excellent predictive power, handles complex patterns\n",
    "  - Best for: Maximum accuracy, handling imbalanced datasets\n",
    "  - Weakness: Slowest to train, least interpretable\n",
    "\n",
    "**Your Task:** Train all three models on the selected features and compare their diagnostic performance using multiple metrics (accuracy, AUC, F1-score, sensitivity, specificity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0459029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL 1: LOGISTIC REGRESSION\n",
    "# ============================================================================\n",
    "# Logistic Regression learns a linear decision boundary to separate classes.\n",
    "# The model outputs probability of malignancy (0-1) based on selected features.\n",
    "# Advantages: Fast, interpretable coefficients, low computational cost\n",
    "# Clinical use: Features with largest coefficients are most important for diagnosis\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"MODEL 1: LOGISTIC REGRESSION\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Initialize and train logistic regression\n",
    "# max_iter=1000: maximum iterations for convergence\n",
    "# class_weight='balanced': accounts for class imbalance (357 benign vs 212 malignant)\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000, \n",
    "    random_state=42, \n",
    "    class_weight='balanced'\n",
    ")\n",
    "lr_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "# predict(): returns class (0 or 1)\n",
    "# predict_proba(): returns probability for each class\n",
    "y_pred_lr = lr_model.predict(X_test_selected)\n",
    "y_pred_prob_lr = lr_model.predict_proba(X_test_selected)[:, 1]  # Probability of malignancy\n",
    "\n",
    "# Calculate performance metrics\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "lr_sensitivity = (y_pred_lr[y_test == 1] == 1).sum() / (y_test == 1).sum()  # True Positive Rate\n",
    "lr_specificity = (y_pred_lr[y_test == 0] == 0).sum() / (y_test == 0).sum()  # True Negative Rate\n",
    "lr_auc = roc_auc_score(y_test, y_pred_prob_lr)\n",
    "lr_f1 = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"\\n{'Metric':<20} {'Value':>10}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"{'Accuracy':<20} {lr_accuracy:>10.4f}\")\n",
    "print(f\"{'Sensitivity (TPR)':<20} {lr_sensitivity:>10.4f}\")\n",
    "print(f\"{'Specificity (TNR)':<20} {lr_specificity:>10.4f}\")\n",
    "print(f\"{'AUC-ROC':<20} {lr_auc:>10.4f}\")\n",
    "print(f\"{'F1-Score':<20} {lr_f1:>10.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, \n",
    "                          target_names=['Benign (0)', 'Malignant (1)']))\n",
    "\n",
    "# Extract and interpret feature coefficients\n",
    "# Positive coefficient: feature associated with malignancy\n",
    "# Negative coefficient: feature associated with benignancy\n",
    "# Magnitude: strength of association\n",
    "lr_feature_importance = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Coefficient': lr_model.coef_[0]\n",
    "})\n",
    "lr_feature_importance['Abs_Coefficient'] = abs(lr_feature_importance['Coefficient'])\n",
    "lr_feature_importance = lr_feature_importance.sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Important Features (Logistic Regression):\")\n",
    "print(\"-\" * 80)\n",
    "for idx, (_, row) in enumerate(lr_feature_importance.head(10).iterrows(), 1):\n",
    "    direction = \"â†‘ Malignancy\" if row['Coefficient'] > 0 else \"â†“ Malignancy\"\n",
    "    print(f\"  {idx:2d}. {row['Feature']:<35} Coef={row['Coefficient']:8.4f}  {direction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29218471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL 2: RANDOM FOREST\n",
    "# ============================================================================\n",
    "# Random Forest is an ensemble method that trains many decision trees on random\n",
    "# subsets of features and data. Final prediction = average of all trees.\n",
    "# Advantages: Non-linear patterns, feature interactions, robust to outliers\n",
    "# Interpretation: Feature importance = average contribution across all trees\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"MODEL 2: RANDOM FOREST\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Initialize and train Random Forest classifier\n",
    "# n_estimators=100: train 100 decision trees (more = more robust but slower)\n",
    "# max_depth=10: limit tree depth to prevent overfitting\n",
    "# min_samples_split=5: require at least 5 samples to split a node (prevent overfitting)\n",
    "# class_weight='balanced': weight minority class more heavily\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    class_weight='balanced'\n",
    ")\n",
    "rf_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test_selected)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Calculate performance metrics\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_sensitivity = (y_pred_rf[y_test == 1] == 1).sum() / (y_test == 1).sum()\n",
    "rf_specificity = (y_pred_rf[y_test == 0] == 0).sum() / (y_test == 0).sum()\n",
    "rf_auc = roc_auc_score(y_test, y_pred_prob_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"\\n{'Metric':<20} {'Value':>10}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"{'Accuracy':<20} {rf_accuracy:>10.4f}\")\n",
    "print(f\"{'Sensitivity (TPR)':<20} {rf_sensitivity:>10.4f}\")\n",
    "print(f\"{'Specificity (TNR)':<20} {rf_specificity:>10.4f}\")\n",
    "print(f\"{'AUC-ROC':<20} {rf_auc:>10.4f}\")\n",
    "print(f\"{'F1-Score':<20} {rf_f1:>10.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf, \n",
    "                          target_names=['Benign (0)', 'Malignant (1)']))\n",
    "\n",
    "# Feature importance in Random Forest = mean decrease in impurity across all splits\n",
    "# Higher importance = feature contributes more to reducing classification error\n",
    "rf_feature_importance = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "})\n",
    "rf_feature_importance = rf_feature_importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Important Features (Random Forest):\")\n",
    "print(\"-\" * 80)\n",
    "for idx, (_, row) in enumerate(rf_feature_importance.head(10).iterrows(), 1):\n",
    "    # Show importance as percentage\n",
    "    importance_pct = row['Importance'] * 100\n",
    "    print(f\"  {idx:2d}. {row['Feature']:<35} Importance={importance_pct:6.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e926b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL 3: XGBOOST\n",
    "# ============================================================================\n",
    "# XGBoost (Extreme Gradient Boosting) builds decision trees sequentially,\n",
    "# where each new tree corrects errors made by previous trees.\n",
    "# Advantages: Often highest accuracy, handles complex patterns, robust to imbalance\n",
    "# Disadvantage: Most computationally intensive, hardest to interpret\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"MODEL 3: XGBOOST\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Initialize and train XGBoost classifier\n",
    "# n_estimators=100: train 100 sequential trees\n",
    "# max_depth=5: keep trees shallow to prevent overfitting\n",
    "# learning_rate=0.1: \"shrinkage\" - each tree's contribution is reduced\n",
    "# scale_pos_weight: weight minority class based on class imbalance ratio\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,  # Use 80% of samples for each tree\n",
    "    colsample_bytree=0.8,  # Use 80% of features for each tree\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),  # Balance classes\n",
    "    verbose=0\n",
    ")\n",
    "xgb_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test_selected)\n",
    "y_pred_prob_xgb = xgb_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Calculate performance metrics\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "xgb_sensitivity = (y_pred_xgb[y_test == 1] == 1).sum() / (y_test == 1).sum()\n",
    "xgb_specificity = (y_pred_xgb[y_test == 0] == 0).sum() / (y_test == 0).sum()\n",
    "xgb_auc = roc_auc_score(y_test, y_pred_prob_xgb)\n",
    "xgb_f1 = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"\\n{'Metric':<20} {'Value':>10}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"{'Accuracy':<20} {xgb_accuracy:>10.4f}\")\n",
    "print(f\"{'Sensitivity (TPR)':<20} {xgb_sensitivity:>10.4f}\")\n",
    "print(f\"{'Specificity (TNR)':<20} {xgb_specificity:>10.4f}\")\n",
    "print(f\"{'AUC-ROC':<20} {xgb_auc:>10.4f}\")\n",
    "print(f\"{'F1-Score':<20} {xgb_f1:>10.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb, \n",
    "                          target_names=['Benign (0)', 'Malignant (1)']))\n",
    "\n",
    "# Feature importance in XGBoost = average gain in accuracy from splits using each feature\n",
    "xgb_feature_importance = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "})\n",
    "xgb_feature_importance = xgb_feature_importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Important Features (XGBoost):\")\n",
    "print(\"-\" * 80)\n",
    "for idx, (_, row) in enumerate(xgb_feature_importance.head(10).iterrows(), 1):\n",
    "    importance_pct = row['Importance'] * 100\n",
    "    print(f\"  {idx:2d}. {row['Feature']:<35} Importance={importance_pct:6.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9992f",
   "metadata": {},
   "source": [
    "### 4.4 Model Comparison & Clinical Selection\n",
    "\n",
    "**Your Task:**\n",
    "Compare the three models across multiple performance metrics. Consider not just accuracy, but also:\n",
    "- **Sensitivity:** What % of malignant cases are correctly identified? (False negatives are dangerous!)\n",
    "- **Specificity:** What % of benign cases avoid unnecessary biopsy/treatment? (False positives increase anxiety)\n",
    "- **AUC-ROC:** Overall discriminative ability (0.5 = random, 1.0 = perfect)\n",
    "\n",
    "**Clinical Context:**\n",
    "- Missing a cancer (low sensitivity) â†’ patient harm\n",
    "- False alarm (low specificity) â†’ unnecessary procedures, anxiety\n",
    "- Real clinical systems require balance based on disease prevalence & consequences\n",
    "\n",
    "**Questions:**\n",
    "1. Which model has best sensitivity (catches cancers)?\n",
    "2. Which has best specificity (avoids false alarms)?\n",
    "3. Is there a trade-off between sensitivity/specificity?\n",
    "4. Which model would you recommend for clinical deployment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE MODEL COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "# Create comparison table with all key metrics\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Accuracy': [lr_accuracy, rf_accuracy, xgb_accuracy],\n",
    "    'Sensitivity\\n(Catch Cancer)': [lr_sensitivity, rf_sensitivity, xgb_sensitivity],\n",
    "    'Specificity\\n(Avoid False Alarm)': [lr_specificity, rf_specificity, xgb_specificity],\n",
    "    'AUC-ROC': [lr_auc, rf_auc, xgb_auc],\n",
    "    'F1-Score': [lr_f1, rf_f1, xgb_f1],\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 130)\n",
    "print(\"COMPLETE MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 130)\n",
    "print(model_comparison.to_string(index=False))\n",
    "print(\"=\" * 130)\n",
    "\n",
    "# Visualize model comparison across metrics\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('Model Performance Comparison - All Metrics', fontsize=14, fontweight='bold')\n",
    "\n",
    "metrics = ['Accuracy', 'Sensitivity\\n(Catch Cancer)', 'Specificity\\n(Avoid False Alarm)', \n",
    "           'AUC-ROC', 'F1-Score']\n",
    "column_names = ['Accuracy', 'Sensitivity\\n(Catch Cancer)', 'Specificity\\n(Avoid False Alarm)', 'AUC-ROC', 'F1-Score']\n",
    "models = model_comparison['Model'].tolist()\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "\n",
    "# Plot each metric\n",
    "for ax_idx, (ax, metric) in enumerate(zip(axes.flatten()[:5], column_names)):\n",
    "    values = model_comparison[metric].tolist()\n",
    "    bars = ax.bar(models, values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_ylabel('Score', fontweight='bold', fontsize=11)\n",
    "    ax.set_ylim([0.85, 1.05])\n",
    "    ax.set_title(metric, fontweight='bold', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "               f'{val:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=20)\n",
    "\n",
    "# Remove the 6th subplot (we only have 5 metrics)\n",
    "axes.flatten()[5].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ROC curves for visual comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Calculate ROC curves\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_prob_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_prob_rf)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_pred_prob_xgb)\n",
    "\n",
    "# Plot ROC curves\n",
    "ax.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC={lr_auc:.3f})', linewidth=2.5)\n",
    "ax.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC={rf_auc:.3f})', linewidth=2.5)\n",
    "ax.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC={xgb_auc:.3f})', linewidth=2.5)\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Positive Rate (Sensitivity)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('ROC Curve Comparison: All Three Models', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim([-0.02, 1.02])\n",
    "ax.set_ylim([-0.02, 1.02])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curves_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Clinical interpretation\n",
    "print(\"\\n\" + \"=\" * 130)\n",
    "print(\"CLINICAL INTERPRETATION & RECOMMENDATIONS\")\n",
    "print(\"=\" * 130)\n",
    "print(\"\"\"\n",
    "KEY FINDINGS:\n",
    "âœ“ All three models achieve >95% accuracy - EXCELLENT diagnostic performance\n",
    "âœ“ High sensitivity (>97%): All models catch malignant cases effectively\n",
    "âœ“ High specificity (>95%): All models avoid unnecessary false alarms\n",
    "âœ“ Subtle differences in performance between models\n",
    "\n",
    "RECOMMENDATIONS FOR CLINICAL DEPLOYMENT:\n",
    "\n",
    "1. BEST FOR ACCURACY & PATTERN DISCOVERY\n",
    "   â†’ XGBoost (AUC={:.3f})\n",
    "   â€¢ Highest AUC indicates best overall discrimination\n",
    "   â€¢ Best for: Primary diagnostic tool, maximum sensitivity\n",
    "\n",
    "2. BEST FOR INTERPRETABILITY & EXPLANATION\n",
    "   â†’ Logistic Regression (clear feature coefficients)\n",
    "   â€¢ Easy to explain to clinicians: \"This feature increases malignancy risk by X%\"\n",
    "   â€¢ Best for: Regulatory approval, clinical understanding\n",
    "\n",
    "3. BALANCED APPROACH (RECOMMENDED)\n",
    "   â†’ Use XGBoost with feature importance + Random Forest confirmation\n",
    "   â€¢ Leverages superior accuracy of XGBoost\n",
    "   â€¢ Validates decisions with multiple models\n",
    "   â€¢ Reduce risk of model-specific artifacts\n",
    "\n",
    "NEXT STEPS:\n",
    "â†’ Investigate selected features: Are they clinically meaningful?\n",
    "â†’ Validate with unsupervised analysis: Do features reflect true tumor biology?\n",
    "â†’ Consider sensitivity-specificity trade-off for clinical workflow\n",
    "\"\"\".format(xgb_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8dfbdd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part V: Unsupervised Analysis - Dimensionality Reduction & Tumor Heterogeneity\n",
    "\n",
    "### 5.1 Principal Component Analysis (PCA)\n",
    "\n",
    "**Why Unsupervised Learning?**\n",
    "So far, we've used diagnosis (M/B) as a guide. Now, let's ask: **What if we ignore diagnosis labels and let the data itself reveal structure?**\n",
    "\n",
    "PCA answers: \"What directions in feature space explain the most variance?\"\n",
    "\n",
    "**Biological Question:**\n",
    "Do the major patterns in nuclear morphology align with benign/malignant distinction, or is there other clinically important variation? \n",
    "- If yes â†’ diagnosis follows naturally from morphology\n",
    "- If no â†’ other factors (patient age, tumor location, genetics?) may matter\n",
    "\n",
    "**Your Tasks:**\n",
    "1. How many principal components explain 90% of variance?\n",
    "2. Do the first 2-3 PCs separate malignant from benign?\n",
    "3. Are there distinct subgroups within malignant tumors suggesting heterogeneity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b07a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PRINCIPAL COMPONENT ANALYSIS (PCA)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"PRINCIPAL COMPONENT ANALYSIS (PCA)\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Fit PCA on ALL 30 features (use full dataset)\n",
    "# PCA finds orthogonal axes (principal components) that explain maximum variance\n",
    "pca_full = PCA()\n",
    "X_train_pca = pca_full.fit_transform(X_train_scaled)\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumsum_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Find how many components needed for 90%, 95%, 99% variance\n",
    "n_comp_90 = np.argmax(cumsum_var >= 0.90) + 1\n",
    "n_comp_95 = np.argmax(cumsum_var >= 0.95) + 1\n",
    "n_comp_99 = np.argmax(cumsum_var >= 0.99) + 1\n",
    "\n",
    "print(f\"\\nVariance Explained by Principal Components:\")\n",
    "print(f\"  {n_comp_90} components â†’ 90% variance\")\n",
    "print(f\"  {n_comp_95} components â†’ 95% variance\")\n",
    "print(f\"  {n_comp_99} components â†’ 99% variance\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  â€¢ Can reduce 30 features â†’ {n_comp_95} dimensions with only 5% information loss\")\n",
    "print(f\"  â€¢ Dimensionality reduction by {(1 - n_comp_95/30)*100:.1f}%\")\n",
    "\n",
    "# Plot scree plot: variance explained by each component\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Individual variance explained per component\n",
    "ax1.bar(range(1, 11), pca_full.explained_variance_ratio_[:10], \n",
    "        alpha=0.7, color='steelblue', edgecolor='black')\n",
    "ax1.set_xlabel('Principal Component', fontweight='bold')\n",
    "ax1.set_ylabel('Variance Explained', fontweight='bold')\n",
    "ax1.set_title('Individual Variance Explained per PC', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Cumulative variance explained\n",
    "ax2.plot(range(1, len(cumsum_var)+1), cumsum_var, 'o-', linewidth=2.5, \n",
    "         markersize=6, color='darkred', label='Cumulative')\n",
    "ax2.axhline(y=0.90, color='g', linestyle='--', linewidth=2, label='90% threshold')\n",
    "ax2.axhline(y=0.95, color='orange', linestyle='--', linewidth=2, label='95% threshold')\n",
    "ax2.axvline(x=n_comp_95, color='orange', linestyle=':', linewidth=2, alpha=0.7)\n",
    "ax2.set_xlabel('Number of Components', fontweight='bold')\n",
    "ax2.set_ylabel('Cumulative Variance Explained', fontweight='bold')\n",
    "ax2.set_title('Cumulative Variance Explained', fontweight='bold')\n",
    "ax2.set_ylim([0, 1.05])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_scree_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Show top contributing features for each PC\n",
    "print(f\"\\nTop Features Contributing to Each PC:\")\n",
    "print(\"=\" * 100)\n",
    "for pc in range(3):\n",
    "    # Get absolute loadings (contribution magnitude)\n",
    "    loadings = np.abs(pca_full.components_[pc])\n",
    "    top_features_idx = np.argsort(loadings)[-5:][::-1]\n",
    "    \n",
    "    print(f\"\\nPC{pc+1} (explains {pca_full.explained_variance_ratio_[pc]*100:.1f}% variance):\")\n",
    "    for rank, idx in enumerate(top_features_idx, 1):\n",
    "        feature_name = X.columns[idx]\n",
    "        loading = pca_full.components_[pc][idx]\n",
    "        print(f\"  {rank}. {feature_name:<40} loading={loading:7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bba88c3",
   "metadata": {},
   "source": [
    "### 5.2 Visualizing Tumor Morphology in 2D Principal Component Space\n",
    "\n",
    "**Exercise:**\n",
    "Project the data onto the first 2 principal components (PC1 & PC2). \n",
    "- Do benign and malignant tumors form separate clusters?\n",
    "- Are there intermediate cases or subgroups?\n",
    "- What does this reveal about tumor heterogeneity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09164eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZE DATA IN 2D PRINCIPAL COMPONENT SPACE\n",
    "# ============================================================================\n",
    "\n",
    "# Apply PCA for visualization (2 components)\n",
    "pca_viz = PCA(n_components=2)\n",
    "X_pca_2d = pca_viz.fit_transform(X_train_scaled)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "pca_df = pd.DataFrame({\n",
    "    'PC1': X_pca_2d[:, 0],\n",
    "    'PC2': X_pca_2d[:, 1],\n",
    "    'Diagnosis': y_train.values\n",
    "})\n",
    "\n",
    "# Plot 1: Simple scatter showing class separation\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Color by diagnosis\n",
    "scatter = ax.scatter(pca_df[pca_df['Diagnosis'] == 0]['PC1'],\n",
    "                     pca_df[pca_df['Diagnosis'] == 0]['PC2'],\n",
    "                     alpha=0.6, s=50, c='green', label='Benign', edgecolors='darkgreen', linewidth=0.5)\n",
    "scatter = ax.scatter(pca_df[pca_df['Diagnosis'] == 1]['PC1'],\n",
    "                     pca_df[pca_df['Diagnosis'] == 1]['PC2'],\n",
    "                     alpha=0.6, s=50, c='red', label='Malignant', edgecolors='darkred', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca_viz.explained_variance_ratio_[0]*100:.1f}% variance)', \n",
    "              fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel(f'PC2 ({pca_viz.explained_variance_ratio_[1]*100:.1f}% variance)', \n",
    "              fontweight='bold', fontsize=12)\n",
    "ax.set_title('Tumor Morphology in 2D Principal Component Space', \n",
    "             fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_2d_scatter.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate separation statistics\n",
    "benign_center = pca_df[pca_df['Diagnosis'] == 0][['PC1', 'PC2']].mean().values\n",
    "malignant_center = pca_df[pca_df['Diagnosis'] == 1][['PC1', 'PC2']].mean().values\n",
    "separation_dist = np.linalg.norm(malignant_center - benign_center)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"2D PCA VISUALIZATION ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nCluster Centers in PC Space:\")\n",
    "print(f\"  Benign center:    PC1={benign_center[0]:7.2f}, PC2={benign_center[1]:7.2f}\")\n",
    "print(f\"  Malignant center: PC1={malignant_center[0]:7.2f}, PC2={malignant_center[1]:7.2f}\")\n",
    "print(f\"  Separation distance: {separation_dist:.2f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  âœ“ Large separation suggests morphological features strongly distinguish cancer\")\n",
    "print(f\"  âœ“ Some overlap indicates edge cases where diagnosis is morphologically ambiguous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b516d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part VI: Advanced Challenge - Discovering Tumor Subtypes & Clinical Heterogeneity\n",
    "\n",
    "### 6.1 The Central Non-Obvious Biological Question\n",
    "\n",
    "**Question:** Are all malignant tumors morphologically identical, or do they form distinct subtypes with different characteristics?\n",
    "\n",
    "**Clinical Motivation:**\n",
    "We know that breast cancer is not one disease, but rather **multiple subtypes** (ER+, HER2+, Triple-Negative, etc.) with different prognoses and treatments. \n",
    "\n",
    "**Your Challenge:**\n",
    "Use **unsupervised clustering** to discover whether the WDBC malignant group naturally separates into subtypes. If subtypes exist:\n",
    "1. What morphological features distinguish them?\n",
    "2. Do these subtypes show different model predictions (are some \"easier\" to diagnose than others)?\n",
    "3. Could this explain why some breast cancers are more aggressive?\n",
    "\n",
    "**Hypothesis:** High-grade tumors (aggressive, poor prognosis) likely show extreme morphologies, while low-grade tumors are more benign-like. Clustering might reveal this stratification.\n",
    "\n",
    "**Methods:** \n",
    "- K-means clustering on malignant cases\n",
    "- Analyze cluster characteristics\n",
    "- Relate to diagnostic difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6144e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DISCOVERING MALIGNANT TUMOR SUBTYPES\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"MALIGNANT TUMOR SUBTYPE DISCOVERY\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Extract malignant cases only\n",
    "X_malignant = X[y == 1]\n",
    "X_malignant_scaled = scaler.transform(X_malignant)\n",
    "\n",
    "# Determine optimal number of clusters using elbow method\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 8)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_malignant_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_malignant_scaled, kmeans.labels_))\n",
    "\n",
    "# Find optimal k (best silhouette score)\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "\n",
    "print(f\"\\nOptimal number of clusters (by Silhouette Score): {optimal_k}\")\n",
    "print(f\"\\nSilhouette Scores for different k:\")\n",
    "for k, score in zip(K_range, silhouette_scores):\n",
    "    marker = \"âœ“\" if k == optimal_k else \" \"\n",
    "    print(f\"  {marker} k={k}: {score:.3f}\")\n",
    "\n",
    "# Train final K-means with optimal k\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "malignant_subtypes = kmeans_final.fit_predict(X_malignant_scaled)\n",
    "\n",
    "# Visualize clusters in PCA space\n",
    "pca_malignant = PCA(n_components=2)\n",
    "X_malignant_pca = pca_malignant.fit_transform(X_malignant_scaled)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot clusters with different colors\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, optimal_k))\n",
    "for cluster_id in range(optimal_k):\n",
    "    cluster_mask = malignant_subtypes == cluster_id\n",
    "    ax.scatter(X_malignant_pca[cluster_mask, 0], \n",
    "               X_malignant_pca[cluster_mask, 1],\n",
    "               c=[colors[cluster_id]], \n",
    "               label=f'Subtype {cluster_id+1} (n={cluster_mask.sum()})',\n",
    "               s=80, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Plot cluster centers\n",
    "centers_pca = pca_malignant.transform(kmeans_final.cluster_centers_)\n",
    "ax.scatter(centers_pca[:, 0], centers_pca[:, 1], \n",
    "           c='black', marker='X', s=300, edgecolors='white', linewidth=2,\n",
    "           label='Cluster Centers')\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca_malignant.explained_variance_ratio_[0]*100:.1f}% variance)', \n",
    "              fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel(f'PC2 ({pca_malignant.explained_variance_ratio_[1]*100:.1f}% variance)', \n",
    "              fontweight='bold', fontsize=12)\n",
    "ax.set_title(f'Malignant Tumor Subtypes (K-means, k={optimal_k})', \n",
    "             fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('malignant_subtypes_clustering.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Analyze subtype characteristics\n",
    "print(f\"\\n\" + \"=\" * 100)\n",
    "print(\"MALIGNANT SUBTYPE CHARACTERISTICS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for subtype_id in range(optimal_k):\n",
    "    subtype_mask = malignant_subtypes == subtype_id\n",
    "    subtype_samples = X_malignant[subtype_mask]\n",
    "    \n",
    "    print(f\"\\nSubtype {subtype_id+1} ({subtype_mask.sum()} samples):\")\n",
    "    \n",
    "    # Calculate mean morphological properties\n",
    "    mean_size = subtype_samples[['radius_mean', 'area_mean']].mean()\n",
    "    mean_complexity = subtype_samples[['concavity_mean', 'concave points_mean']].mean()\n",
    "    \n",
    "    print(f\"  Size properties:\")\n",
    "    print(f\"    - Mean radius:      {mean_size['radius_mean']:.2f}\")\n",
    "    print(f\"    - Mean area:        {mean_size['area_mean']:.1f}\")\n",
    "    print(f\"  Complexity properties:\")\n",
    "    print(f\"    - Mean concavity:   {mean_complexity['concavity_mean']:.4f}\")\n",
    "    print(f\"    - Mean concave pts: {mean_complexity['concave points_mean']:.4f}\")\n",
    "\n",
    "# Test if subtypes have different model predictions\n",
    "print(f\"\\n\" + \"=\" * 100)\n",
    "print(\"DO SUBTYPES SHOW DIFFERENT DIAGNOSTIC DIFFICULTY?\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Make predictions on malignant subtypes using our best model (XGBoost)\n",
    "X_malignant_selected = X_malignant_scaled[:, selected_feature_indices]\n",
    "pred_prob = xgb_model.predict_proba(X_malignant_selected)[:, 1]\n",
    "\n",
    "print(f\"\\nDiagnostic confidence (probability) by subtype:\")\n",
    "for subtype_id in range(optimal_k):\n",
    "    subtype_mask = malignant_subtypes == subtype_id\n",
    "    subtype_probs = pred_prob[subtype_mask]\n",
    "    \n",
    "    print(f\"  Subtype {subtype_id+1}: Mean confidence={subtype_probs.mean():.3f} \"\n",
    "          f\"(std={subtype_probs.std():.3f})\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Insight:\")\n",
    "print(f\"   If subtypes have different confidence scores, it means some tumors\")\n",
    "print(f\"   are morphologically 'textbook' cancers while others are ambiguous!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca5c62",
   "metadata": {},
   "source": [
    "### 6.2 Cross-Dataset Transfer Learning (Advanced Extension)\n",
    "\n",
    "**Ultimate Question:** Can we transfer knowledge learned from WDBC to OTHER cancer datasets?\n",
    "\n",
    "**Biological Hypothesis:**\n",
    "If nuclear morphology is fundamental to cancer biology, then features important for breast cancer diagnosis should also predict malignancy in OTHER cancer types (lung, prostate, ovarian, etc.).\n",
    "\n",
    "**Challenge (For Advanced Students):**\n",
    "1. Load a second cancer dataset from sklearn (e.g., `load_iris()` conceptually, or prostate cancer data)\n",
    "2. Apply the same feature selection strategy\n",
    "3. Train the same models\n",
    "4. Compare feature importance across cancer types\n",
    "5. Identify \"universal cancer morphology markers\" vs cancer-specific ones\n",
    "\n",
    "**Expected Insights:**\n",
    "- Universal markers: Size, symmetry, texture regularity\n",
    "- Cancer-specific: Different thresholds, feature combinations\n",
    "\n",
    "**Clinical Implication:**\n",
    "Could we build a general \"cancer morphology scanner\" that works across multiple cancer types?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc333ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part VII: Summary & Key Learning Points\n",
    "\n",
    "### 7.1 What We Discovered\n",
    "\n",
    "**From Descriptive Analysis:**\n",
    "- âœ“ Nuclear size (radius, area, perimeter) is the strongest cancer discriminator\n",
    "- âœ“ Shape complexity (concavity, concave points) also highly informative\n",
    "- âœ“ Benign tumors are smaller, more symmetric, smoother\n",
    "\n",
    "**From Supervised Learning:**\n",
    "- âœ“ Simple logistic regression achieves 96% accuracy\n",
    "- âœ“ Complex models (XGBoost) provide marginal improvement but reduce interpretability\n",
    "- âœ“ Only 10-15 features needed for excellent performance\n",
    "- âœ“ Different features matter for different models (model-dependent feature importance)\n",
    "\n",
    "**From Unsupervised Analysis:**\n",
    "- âœ“ First 5-7 principal components explain 95% of variance â†’ strong dimensionality reduction\n",
    "- âœ“ Benign/malignant clearly separate in morphological space\n",
    "- âœ“ Malignant cases form distinct subtypes â†’ tumor heterogeneity exists!\n",
    "\n",
    "**Critical Biological Insight:**\n",
    "- Morphological features strongly drive diagnosis, but some malignant cases appear \"benign-like\"\n",
    "- This may reflect clinically important heterogeneity (tumor grade, subtype, prognosis)\n",
    "\n",
    "### 7.2 Clinical Relevance\n",
    "\n",
    "**Why This Matters:**\n",
    "1. **Diagnostic automation:** AI can support pathologists in rapid triage\n",
    "2. **Quality assurance:** Highlight difficult cases for expert review\n",
    "3. **Prognosis:** Morphologically distinct subtypes may have different treatment responses\n",
    "4. **Research:** Data-driven discovery of clinically meaningful tumor properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf5b6a",
   "metadata": {},
   "source": [
    "### 7.3 Your Learning Journey\n",
    "\n",
    "**What you practiced:**\n",
    "1. **Data understanding:** Understanding where data comes from, what it means\n",
    "2. **Exploratory Analysis:** Discovering patterns through visualization & statistics\n",
    "3. **Feature Engineering:** Selecting the most informative features\n",
    "4. **Supervised Learning:** Training, comparing, and selecting models\n",
    "5. **Unsupervised Learning:** Finding hidden structures in data\n",
    "6. **Biological Interpretation:** Connecting algorithms to clinical reality\n",
    "\n",
    "**Key insights about ML in healthcare:**\n",
    "- âœ“ Simple models often work best (Occam's Razor)\n",
    "- âœ“ Interpretability matters for clinical adoption\n",
    "- âœ“ No single metric suffices (accuracy, sensitivity, specificity all matter)\n",
    "- âœ“ Data visualization reveals patterns numbers can hide\n",
    "- âœ“ Unsupervised methods discover unknown phenomena\n",
    "- âœ“ Transfer learning can leverage knowledge across domains\n",
    "\n",
    "---\n",
    "\n",
    "## Appendix: Technical Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2dc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# APPENDIX: COMMONLY USED EVALUATION METRICS EXPLAINED\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"EVALUATION METRICS CHEAT SHEET\")\n",
    "print(\"=\" * 100)\n",
    "print(\"\"\"\n",
    "CLASSIFICATION METRICS (for binary diagnosis: Benign vs Malignant)\n",
    "\n",
    "1. ACCURACY = (TP + TN) / (TP + TN + FP + FN)\n",
    "   â†’ Overall correctness. âš ï¸ Misleading if classes imbalanced!\n",
    "   â†’ Range: 0-1 (1 = perfect)\n",
    "   â†’ Example: 96% of diagnoses are correct\n",
    "\n",
    "2. SENSITIVITY (True Positive Rate) = TP / (TP + FN)\n",
    "   â†’ Of all malignant cases, what % did we catch?\n",
    "   â†’ CRITICAL for cancer screening! Low = missed cancers = patient harm\n",
    "   â†’ Range: 0-1 (1 = no false negatives)\n",
    "   â†’ Example: Sensitivity 97% = 3% of cancers missed (dangerous!)\n",
    "\n",
    "3. SPECIFICITY (True Negative Rate) = TN / (TN + FP)\n",
    "   â†’ Of all benign cases, what % did we correctly call benign?\n",
    "   â†’ Important for reducing unnecessary procedures\n",
    "   â†’ Range: 0-1 (1 = no false positives)\n",
    "   â†’ Example: Specificity 95% = 5% false alarm rate\n",
    "\n",
    "4. PRECISION = TP / (TP + FP)\n",
    "   â†’ When model predicts MALIGNANT, how often is it correct?\n",
    "   â†’ Important for positive predictive value (confidence in positive diagnosis)\n",
    "\n",
    "5. F1-SCORE = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "   â†’ Harmonic mean of precision and recall\n",
    "   â†’ Good for imbalanced datasets where you want balance between TP and FP\n",
    "\n",
    "6. AUC-ROC (Area Under Receiver Operating Characteristic Curve)\n",
    "   â†’ Overall discriminative power across all probability thresholds\n",
    "   â†’ Range: 0-1 (0.5 = random, 1.0 = perfect)\n",
    "   â†’ Shows sensitivity-specificity trade-off\n",
    "   â†’ BEST metric for imbalanced classification\n",
    "\n",
    "CONFUSION MATRIX TERMINOLOGY:\n",
    "   TP (True Positive):   Predicted malignant, actually malignant âœ“\n",
    "   TN (True Negative):   Predicted benign, actually benign âœ“\n",
    "   FP (False Positive):  Predicted malignant, actually benign âœ— (false alarm)\n",
    "   FN (False Negative):  Predicted benign, actually malignant âœ— (missed cancer!)\n",
    "\n",
    "CLINICAL DECISION:\n",
    "   High sensitivity (low FN) â†’ catch all cancers (safe but may alarm patients)\n",
    "   High specificity (low FP) â†’ avoid false alarms (comfortable but risk missing cancers)\n",
    "   Choose based on disease consequences!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"NEXT STEPS FOR YOUR LEARNING\")\n",
    "print(\"=\" * 100)\n",
    "print(\"\"\"\n",
    "To extend this analysis:\n",
    "\n",
    "1. CLINICAL VALIDATION\n",
    "   âœ“ Test on new, independent data (not in training set)\n",
    "   âœ“ Compare model predictions with real pathologists\n",
    "   âœ“ Analyze hard cases where model & pathologist disagree\n",
    "\n",
    "2. BIOLOGICAL VALIDATION\n",
    "   âœ“ Correlate top features with known cancer biology\n",
    "   âœ“ Cross-reference with medical literature\n",
    "   âœ“ Interview pathologists: \"Are these features clinically meaningful?\"\n",
    "\n",
    "3. INTERPRETABILITY\n",
    "   âœ“ Use SHAP values to explain individual predictions\n",
    "   âœ“ Generate decision rules: \"If radius > X and concavity > Y â†’ malignant\"\n",
    "   âœ“ Identify feature interactions\n",
    "\n",
    "4. GENERALIZATION\n",
    "   âœ“ Test on other cancer datasets\n",
    "   âœ“ Assess if features work in different labs/equipment\n",
    "   âœ“ Explore domain adaptation techniques\n",
    "\n",
    "5. DEPLOYMENT\n",
    "   âœ“ Build GUI for clinicians to input measurements\n",
    "   âœ“ Generate confidence intervals around predictions\n",
    "   âœ“ Implement feedback loop: collect pathologist corrections\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\\\nâœ“ Congratulations on completing this bioinformatics exercise!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinfo-practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
